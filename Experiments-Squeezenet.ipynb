{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import datetime\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torchvision.models import squeezenet, alexnet, inception_v3\n",
    "from torchvision.datasets import coco\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mem_size(t):\n",
    "    t_size = t.size()\n",
    "    n_nums = 1\n",
    "    for n in t_size:\n",
    "        n_nums *= n\n",
    "    bit_size_map = {torch.float32 : 32, torch.float16 : 16, torch.float64 : 64, torch.uint8 : 8, torch.int8 : 8, torch.int16 : 16, torch.int32 : 32, torch.int64 : 64}\n",
    "    return (n_nums * bit_size_map[t.dtype]) / 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = '/Users/peterspradling/CS349D'\n",
    "ANN_PATH = '/coco/cocoapi/annotations/instances_val2017.json'\n",
    "VAL_PATH = '/coco/cocoapi/images/val2017/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_coco(l):\n",
    "    return torch.stack([x[0] for x in l])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Squeezenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.86s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "squeezenet_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "#                                      std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "squeezenet_dataset = coco.CocoDetection(root=BASE+VAL_PATH, annFile=BASE+ANN_PATH, transform=squeezenet_transform)\n",
    "squeezenet_eval_loader = torch.utils.data.DataLoader(squeezenet_dataset, batch_size=1, shuffle=True, collate_fn=merge_coco)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/peterspradling/anaconda3/envs/torch/lib/python3.5/site-packages/torchvision-0.2.1-py3.5.egg/torchvision/models/squeezenet.py:94: UserWarning: nn.init.kaiming_uniform is now deprecated in favor of nn.init.kaiming_uniform_.\n",
      "/Users/peterspradling/anaconda3/envs/torch/lib/python3.5/site-packages/torchvision-0.2.1-py3.5.egg/torchvision/models/squeezenet.py:92: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
      "Downloading: \"https://download.pytorch.org/models/squeezenet1_0-a815701f.pth\" to /Users/peterspradling/.torch/models/squeezenet1_0-a815701f.pth\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "squeezenet_model = squeezenet.squeezenet1_0(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squeezenet_measure_forward(model, x):\n",
    "    print('Image size:', compute_mem_size(x))\n",
    "    for module in model.features:\n",
    "        t1 = datetime.datetime.now()\n",
    "        x = module(x)\n",
    "        t2 = datetime.datetime.now()\n",
    "        dt1 = t2 - t1\n",
    "        canon_name = type(module).__name__\n",
    "        print('After ' + canon_name + '(' + str(dt1.total_seconds()) + '):  ' + str(compute_mem_size(x)))\n",
    "    # resize step.\n",
    "    #x = x.view(x.size(0), 256 * 6 * 6)\n",
    "    # classification step\n",
    "    for module in model.classifier:\n",
    "        t1 = datetime.datetime.now()\n",
    "        x = module(x)\n",
    "        t2 = datetime.datetime.now()\n",
    "        dt1 = t2 - t1\n",
    "        canon_name = type(module).__name__\n",
    "        print('After ' + canon_name + '(' + str(dt1.total_seconds()) + '):  ' + str(compute_mem_size(x)))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image size: 602112.0\n",
      "After Conv2d(0.007228):  4562304.0\n",
      "After ReLU(0.002917):  4562304.0\n",
      "After MaxPool2d(0.012698):  1119744.0\n",
      "After Fire(0.043687):  1492992.0\n",
      "After Fire(0.018239):  1492992.0\n",
      "After Fire(0.014437):  2985984.0\n",
      "After MaxPool2d(0.013278):  746496.0\n",
      "After Fire(0.008686):  746496.0\n",
      "After Fire(0.005105):  1119744.0\n",
      "After Fire(0.005788):  1119744.0\n",
      "After Fire(0.005746):  1492992.0\n",
      "After MaxPool2d(0.003027):  346112.0\n",
      "After Fire(0.002068):  346112.0\n",
      "After Dropout(9.3e-05):  346112.0\n",
      "After Conv2d(0.002455):  676000.0\n",
      "After ReLU(0.000431):  676000.0\n",
      "After AvgPool2d(0.000298):  4000.0\n"
     ]
    }
   ],
   "source": [
    "squeezenet_model.eval()\n",
    "for batch in squeezenet_eval_loader:\n",
    "    squeezenet_measure_forward(squeezenet_model, batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.CenterCrop(227),\n",
    "    transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "#                                      std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "alexnet_dataset = coco.CocoDetection(root=BASE+VAL_PATH, annFile=BASE+ANN_PATH, transform=resnet_transform)\n",
    "alexnet_eval_loader = torch.utils.data.DataLoader(alexnet_dataset, batch_size=1, shuffle=True, collate_fn=merge_coco)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet_model = alexnet(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alexnet_measure_forward(model, x):\n",
    "    print('Image size: ', compute_mem_size(x))\n",
    "    for module in model.features:\n",
    "        t1 = datetime.datetime.now()\n",
    "        x = module(x)\n",
    "        t2 = datetime.datetime.now()\n",
    "        dt1 = t2 - t1\n",
    "        canon_name = type(module).__name__\n",
    "        print('After ' + canon_name + '(' + str(dt1.total_seconds()) + '):  ' + str(compute_mem_size(x)))\n",
    "    # resize step.\n",
    "    x = x.view(x.size(0), 256 * 6 * 6)\n",
    "    # classification step\n",
    "    for module in model.classifier:\n",
    "        t1 = datetime.datetime.now()\n",
    "        x = module(x)\n",
    "        t2 = datetime.datetime.now()\n",
    "        dt1 = t2 - t1\n",
    "        canon_name = type(module).__name__\n",
    "        print('After ' + canon_name + '(' + str(dt1.total_seconds()) + '):  ' + str(compute_mem_size(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet_model.eval()\n",
    "for batch in alexnet_eval_loader:\n",
    "    alexnet_measure_forward(alexnet_model, batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inception V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.65s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "inception_transform = transforms.Compose([\n",
    "    transforms.Resize((299, 299)),\n",
    "    transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "#                                      std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "inception_dataset = coco.CocoDetection(root=BASE+VAL_PATH, annFile=BASE+ANN_PATH, transform=inception_transform)\n",
    "inception_eval_loader = torch.utils.data.DataLoader(inception_dataset, batch_size=1, shuffle=True, collate_fn=merge_coco)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception_model = inception_v3(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# incomplete\n",
    "def inception_measure_forward(model, x):\n",
    "    print('Image size: ', compute_mem_size(x))\n",
    "    # 299 x 299 x 3\n",
    "    t1 = datetime.datetime.now()\n",
    "    x = model.Conv2d_1a_3x3(x)\n",
    "    t2 = datetime.datetime.now()\n",
    "    dt1 = t2 - t1\n",
    "    print('After Conv2d1a (' + str(dt1.total_seconds()) + '):', compute_mem_size(x))\n",
    "    # 149 x 149 x 32\n",
    "    t1 = datetime.datetime.now()\n",
    "    x = model.Conv2d_2a_3x3(x)\n",
    "    t2 = datetime.datetime.now()\n",
    "    dt1 = t2 - t1\n",
    "    print('After Conv2d2a (' + str(dt1.total_seconds()) + '):', compute_mem_size(x))\n",
    "    # 147 x 147 x 32\n",
    "    t1 = datetime.datetime.now()\n",
    "    x = model.Conv2d_2b_3x3(x)\n",
    "    t2 = datetime.datetime.now()\n",
    "    dt1 = t2 - t1\n",
    "    print('After Conv2d2b (' + str(dt1.total_seconds()) + '):', compute_mem_size(x))\n",
    "    # 147 x 147 x 64\n",
    "    t1 = datetime.datetime.now()\n",
    "    x = F.max_pool2d(x, kernel_size=3, stride=2)\n",
    "    t2 = datetime.datetime.now()\n",
    "    dt1 = t2 - t1\n",
    "    print('After MaxPool2d (' + str(dt1.total_seconds()) + '):', compute_mem_size(x))\n",
    "    # 73 x 73 x 64\n",
    "    t1 = datetime.datetime.now()\n",
    "    x = model.Conv2d_3b_1x1(x)\n",
    "    t2 = datetime.datetime.now()\n",
    "    dt1 = t2 - t1\n",
    "    print('After Conv2d3B (' + str(dt1.total_seconds()) + '):', compute_mem_size(x))\n",
    "    # 73 x 73 x 80\n",
    "    t1 = datetime.datetime.now()\n",
    "    x = model.Conv2d_4a_3x3(x)\n",
    "    t2 = datetime.datetime.now()\n",
    "    dt1 = t2 - t1\n",
    "    print('After Conv2d4A (' + str(dt1.total_seconds()) + '):', compute_mem_size(x))\n",
    "    # 71 x 71 x 192\n",
    "    t1 = datetime.datetime.now()\n",
    "    x = F.max_pool2d(x, kernel_size=3, stride=2)\n",
    "    t2 = datetime.datetime.now()\n",
    "    dt1 = t2 - t1\n",
    "    print('After MaxPool2D (' + str(dt1.total_seconds()) + '):', compute_mem_size(x))\n",
    "    # 35 x 35 x 192\n",
    "    t1 = datetime.datetime.now()\n",
    "    x = model.Mixed_5b(x)\n",
    "    t2 = datetime.datetime.now()\n",
    "    dt1 = t2 - t1\n",
    "    print('After Mixed5B (' + str(dt1.total_seconds()) + '):', compute_mem_size(x))\n",
    "    # 35 x 35 x 256\n",
    "    t1 = datetime.datetime.now()\n",
    "    x = model.Mixed_5c(x)\n",
    "    t2 = datetime.datetime.now()\n",
    "    dt1 = t2 - t1\n",
    "    print('After Mixed5C (' + str(dt1.total_seconds()) + '):', compute_mem_size(x))\n",
    "    # 35 x 35 x 288\n",
    "    t1 = datetime.datetime.now()\n",
    "    x = model.Mixed_5d(x)\n",
    "    t2 = datetime.datetime.now()\n",
    "    dt1 = t2 - t1\n",
    "    print('After Mixed5D (' + str(dt1.total_seconds()) + '):', compute_mem_size(x))\n",
    "    # 35 x 35 x 288\n",
    "    t1 = datetime.datetime.now()\n",
    "    x = model.Mixed_6a(x)\n",
    "    t2 = datetime.datetime.now()\n",
    "    dt1 = t2 - t1\n",
    "    print('After Mixed6A (' + str(dt1.total_seconds()) + '):', compute_mem_size(x))\n",
    "    # 17 x 17 x 768\n",
    "    t1 = datetime.datetime.now()\n",
    "    x = model.Mixed_6b(x)\n",
    "    t2 = datetime.datetime.now()\n",
    "    dt1 = t2 - t1\n",
    "    print('After Mixed6B (' + str(dt1.total_seconds()) + '):', compute_mem_size(x))\n",
    "    # 17 x 17 x 768\n",
    "    t1 = datetime.datetime.now()\n",
    "    x = model.Mixed_6c(x)\n",
    "    t2 = datetime.datetime.now()\n",
    "    dt1 = t2 - t1\n",
    "    print('After Mixed6C (' + str(dt1.total_seconds()) + '):', compute_mem_size(x))\n",
    "    # 17 x 17 x 768\n",
    "    t1 = datetime.datetime.now()\n",
    "    x = model.Mixed_6d(x)\n",
    "    t2 = datetime.datetime.now()\n",
    "    dt1 = t2 - t1\n",
    "    print('After Mixed6D (' + str(dt1.total_seconds()) + '):', compute_mem_size(x))\n",
    "    # 17 x 17 x 768\n",
    "    t1 = datetime.datetime.now()\n",
    "    x = model.Mixed_6e(x)\n",
    "    t2 = datetime.datetime.now()\n",
    "    dt1 = t2 - t1\n",
    "    print('After Mixed6E (' + str(dt1.total_seconds()) + '):', compute_mem_size(x))\n",
    "    # 17 x 17 x 768\n",
    "    t1 = datetime.datetime.now()\n",
    "    x = model.Mixed_7a(x)\n",
    "    t2 = datetime.datetime.now()\n",
    "    dt1 = t2 - t1\n",
    "    print('After Mixed7A (' + str(dt1.total_seconds()) + '):', compute_mem_size(x))\n",
    "    # 8 x 8 x 1280\n",
    "    t1 = datetime.datetime.now()\n",
    "    x = model.Mixed_7b(x)\n",
    "    t2 = datetime.datetime.now()\n",
    "    dt1 = t2 - t1\n",
    "    print('After Mixed7B (' + str(dt1.total_seconds()) + '):', compute_mem_size(x))\n",
    "    # 8 x 8 x 2048\n",
    "    t1 = datetime.datetime.now()\n",
    "    x = model.Mixed_7c(x)\n",
    "    t2 = datetime.datetime.now()\n",
    "    dt1 = t2 - t1\n",
    "    print('After Mixed7C (' + str(dt1.total_seconds()) + '):', compute_mem_size(x))\n",
    "    # 8 x 8 x 2048\n",
    "    t1 = datetime.datetime.now()\n",
    "    x = F.avg_pool2d(x, kernel_size=8)\n",
    "    t2 = datetime.datetime.now()\n",
    "    dt1 = t2 - t1\n",
    "    print('After AvgPool2d (' + str(dt1.total_seconds()) + '):', compute_mem_size(x))\n",
    "    # 1 x 1 x 2048\n",
    "    x = F.dropout(x, training=model.training)\n",
    "    # 1 x 1 x 2048\n",
    "    x = x.view(x.size(0), -1)\n",
    "    # 2048\n",
    "    t1 = datetime.datetime.now()\n",
    "    x = model.fc(x)\n",
    "    t2 = datetime.datetime.now()\n",
    "    dt1 = t2 - t1\n",
    "    print('After FC (' + str(dt1.total_seconds()) + '):', compute_mem_size(x))\n",
    "    # 1000 (num_classes)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image size:  1072812.0\n",
      "After Conv2d1a (0.034189): 2841728.0\n",
      "After Conv2d2a (0.024898): 2765952.0\n",
      "After Conv2d2b (0.032337): 5531904.0\n",
      "After MaxPool2d (0.018495): 1364224.0\n",
      "After Conv2d3B (0.010574): 1705280.0\n",
      "After Conv2d4A (0.024739): 3871488.0\n",
      "After MaxPool2D (0.009854): 940800.0\n",
      "After Mixed5B (0.026174): 1254400.0\n",
      "After Mixed5C (0.035077): 1411200.0\n",
      "After Mixed5D (0.047889): 1411200.0\n",
      "After Mixed6A (0.026884): 887808.0\n",
      "After Mixed6B (0.035302): 887808.0\n",
      "After Mixed6C (0.038276): 887808.0\n",
      "After Mixed6D (0.039578): 887808.0\n",
      "After Mixed6E (0.044512): 887808.0\n",
      "After Mixed7A (0.017383): 327680.0\n",
      "After Mixed7B (0.023297): 524288.0\n",
      "After Mixed7C (0.029244): 524288.0\n",
      "After AvgPool2d (0.000436): 8192.0\n",
      "After FC (0.007548): 4000.0\n"
     ]
    }
   ],
   "source": [
    "inception_model.eval()\n",
    "for batch in inception_eval_loader:\n",
    "    inception_measure_forward(inception_model, batch)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch]",
   "language": "python",
   "name": "conda-env-torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
