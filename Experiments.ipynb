{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import datetime\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torchvision.models import resnet, alexnet, inception_v3\n",
    "from torchvision.datasets import coco\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mem_size(t):\n",
    "    t_size = t.size()\n",
    "    n_nums = 1\n",
    "    for n in t_size:\n",
    "        n_nums *= n\n",
    "    bit_size_map = {torch.float32 : 32, torch.float16 : 16, torch.float64 : 64, torch.uint8 : 8, torch.int8 : 8, torch.int16 : 16, torch.int32 : 32, torch.int64 : 64}\n",
    "    return (n_nums * bit_size_map[t.dtype]) / 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = '/Users/ankitmathur/'\n",
    "ANN_PATH = 'datasets/coco/cocoapi/annotations/instances_val2017.json'\n",
    "VAL_PATH = 'datasets/coco/cocoapi/images/val2017/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_coco(l):\n",
    "    return torch.stack([x[0] for x in l])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "#                                      std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "resnet_dataset = coco.CocoDetection(root=BASE+VAL_PATH, annFile=BASE+ANN_PATH, transform=resnet_transform)\n",
    "resnet_eval_loader = torch.utils.data.DataLoader(resnet_dataset, batch_size=1, shuffle=True, collate_fn=merge_coco)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model = resnet.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_measure_forward(model, x):\n",
    "    print('Image size:', compute_mem_size(x))\n",
    "    t0 = datetime.datetime.now()\n",
    "    x = model.conv1(x)\n",
    "    x = model.bn1(x)\n",
    "    x = model.relu(x)\n",
    "    t1 = datetime.datetime.now()\n",
    "    dt1 = t1 - t0\n",
    "    print('After conv1 (' + str(dt1.total_seconds()) + '):', compute_mem_size(x))\n",
    "    t2 = datetime.datetime.now()\n",
    "    x = model.maxpool(x)\n",
    "    t3 = datetime.datetime.now()\n",
    "    dt2 = t3 - t2\n",
    "    print('After maxpool (' + str(dt2.total_seconds()) + '):', compute_mem_size(x))\n",
    "    t4 = datetime.datetime.now()\n",
    "    x = model.layer1(x)\n",
    "    t5 = datetime.datetime.now()\n",
    "    dt3 = t5 - t4\n",
    "    print('After l1 (' + str(dt3.total_seconds()) + '):', compute_mem_size(x))\n",
    "    t6 = datetime.datetime.now()\n",
    "    x = model.layer2(x)\n",
    "    t7 = datetime.datetime.now()\n",
    "    dt4 = t7 - t6\n",
    "    print('After l2 (' + str(dt4.total_seconds()) + '):', compute_mem_size(x))\n",
    "    t8 = datetime.datetime.now()\n",
    "    x = model.layer3(x)\n",
    "    t9 = datetime.datetime.now()\n",
    "    dt5 = t9 - t8\n",
    "    print('After l3 (' + str(dt5.total_seconds()) + '):', compute_mem_size(x))\n",
    "    t10 = datetime.datetime.now()\n",
    "    x = model.layer4(x)\n",
    "    t11 = datetime.datetime.now()\n",
    "    dt6 = t11 - t10\n",
    "    print('After l4 (' + str(dt6.total_seconds()) + '):', compute_mem_size(x))\n",
    "    t12 = datetime.datetime.now()\n",
    "    x = model.avgpool(x)\n",
    "    t13 = datetime.datetime.now()\n",
    "    dt7 = t13 - t12\n",
    "    print('After avgpool (' + str(dt7.total_seconds()) + '):', compute_mem_size(x))\n",
    "    x = x.view(x.size(0), -1)\n",
    "    t14 = datetime.datetime.now()\n",
    "    x = model.fc(x)\n",
    "    t15 = datetime.datetime.now()\n",
    "    dt8 = t15 - t14\n",
    "    print('After fc (' + str(dt8.total_seconds()) + '):', compute_mem_size(x))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model.eval()\n",
    "for batch in resnet_eval_loader:\n",
    "    resnet_measure_forward(resnet_model, batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.CenterCrop(227),\n",
    "    transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "#                                      std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "alexnet_dataset = coco.CocoDetection(root=BASE+VAL_PATH, annFile=BASE+ANN_PATH, transform=resnet_transform)\n",
    "alexnet_eval_loader = torch.utils.data.DataLoader(alexnet_dataset, batch_size=1, shuffle=True, collate_fn=merge_coco)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet_model = alexnet(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alexnet_measure_forward(model, x):\n",
    "    print('Image size: ', compute_mem_size(x))\n",
    "    for module in model.features:\n",
    "        t1 = datetime.datetime.now()\n",
    "        x = module(x)\n",
    "        t2 = datetime.datetime.now()\n",
    "        dt1 = t2 - t1\n",
    "        canon_name = type(module).__name__\n",
    "        print('After ' + canon_name + '(' + str(dt1.total_seconds()) + '):  ' + str(compute_mem_size(x)))\n",
    "    # resize step.\n",
    "    x = x.view(x.size(0), 256 * 6 * 6)\n",
    "    # classification step\n",
    "    for module in model.classifier:\n",
    "        t1 = datetime.datetime.now()\n",
    "        x = module(x)\n",
    "        t2 = datetime.datetime.now()\n",
    "        dt1 = t2 - t1\n",
    "        canon_name = type(module).__name__\n",
    "        print('After ' + canon_name + '(' + str(dt1.total_seconds()) + '):  ' + str(compute_mem_size(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet_model.eval()\n",
    "for batch in alexnet_eval_loader:\n",
    "    alexnet_measure_forward(alexnet_model, batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inception V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.61s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "inception_transform = transforms.Compose([\n",
    "    transforms.Resize((299, 299)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                      std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "inception_dataset = coco.CocoDetection(root=BASE+VAL_PATH, annFile=BASE+ANN_PATH, transform=inception_transform)\n",
    "inception_eval_loader = torch.utils.data.DataLoader(inception_dataset, batch_size=1, shuffle=True, collate_fn=merge_coco)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception_model = inception_v3(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# incomplete\n",
    "def inception_measure_forward(model, x):\n",
    "    print('Image size: ', compute_mem_size(x))\n",
    "    # 299 x 299 x 3\n",
    "    t1 = datetime.datetime.now()\n",
    "    x = model.Conv2d_1a_3x3(x)\n",
    "    t2 = datetime.datetime.now()\n",
    "    dt1 = t2 - t1\n",
    "    print('After Conv2d1a (' + str(dt1.total_seconds()) + '):', compute_mem_size(x))\n",
    "    # 149 x 149 x 32\n",
    "    t1 = datetime.datetime.now()\n",
    "    x = model.Conv2d_2a_3x3(x)\n",
    "    t2 = datetime.datetime.now()\n",
    "    dt1 = t2 - t1\n",
    "    print('After Conv2d2a (' + str(dt1.total_seconds()) + '):', compute_mem_size(x))\n",
    "    # 147 x 147 x 32\n",
    "    t1 = datetime.datetime.now()\n",
    "    x = model.Conv2d_2b_3x3(x)\n",
    "    t2 = datetime.datetime.now()\n",
    "    dt1 = t2 - t1\n",
    "    print('After Conv2d2b (' + str(dt1.total_seconds()) + '):', compute_mem_size(x))\n",
    "    # 147 x 147 x 64\n",
    "    t1 = datetime.datetime.now()\n",
    "    x = F.max_pool2d(x, kernel_size=3, stride=2)\n",
    "    t2 = datetime.datetime.now()\n",
    "    dt1 = t2 - t1\n",
    "    print('After MaxPool2d (' + str(dt1.total_seconds()) + '):', compute_mem_size(x))\n",
    "    # 73 x 73 x 64\n",
    "    t1 = datetime.datetime.now()\n",
    "    x = model.Conv2d_3b_1x1(x)\n",
    "    t2 = datetime.datetime.now()\n",
    "    dt1 = t2 - t1\n",
    "    print('After Conv2d3B (' + str(dt1.total_seconds()) + '):', compute_mem_size(x))\n",
    "    # 73 x 73 x 80\n",
    "    t1 = datetime.datetime.now()\n",
    "    x = model.Conv2d_4a_3x3(x)\n",
    "    t2 = datetime.datetime.now()\n",
    "    dt1 = t2 - t1\n",
    "    print('After Conv2d4A (' + str(dt1.total_seconds()) + '):', compute_mem_size(x))\n",
    "    # 71 x 71 x 192\n",
    "    t1 = datetime.datetime.now()\n",
    "    x = F.max_pool2d(x, kernel_size=3, stride=2)\n",
    "    plt.hist(x.view(-1).data.numpy(), bins=15)\n",
    "    t2 = datetime.datetime.now()\n",
    "    dt1 = t2 - t1\n",
    "    print('After MaxPool2D (' + str(dt1.total_seconds()) + '):', compute_mem_size(x))\n",
    "    # 35 x 35 x 192\n",
    "    t1 = datetime.datetime.now()\n",
    "    x = model.Mixed_5b(x)\n",
    "    t2 = datetime.datetime.now()\n",
    "    dt1 = t2 - t1\n",
    "    print('After Mixed5B (' + str(dt1.total_seconds()) + '):', compute_mem_size(x))\n",
    "    # 35 x 35 x 256\n",
    "    t1 = datetime.datetime.now()\n",
    "    x = model.Mixed_5c(x)\n",
    "    t2 = datetime.datetime.now()\n",
    "    dt1 = t2 - t1\n",
    "    print('After Mixed5C (' + str(dt1.total_seconds()) + '):', compute_mem_size(x))\n",
    "    # 35 x 35 x 288\n",
    "    t1 = datetime.datetime.now()\n",
    "    x = model.Mixed_5d(x)\n",
    "    t2 = datetime.datetime.now()\n",
    "    dt1 = t2 - t1\n",
    "    print('After Mixed5D (' + str(dt1.total_seconds()) + '):', compute_mem_size(x))\n",
    "    # 35 x 35 x 288\n",
    "    t1 = datetime.datetime.now()\n",
    "    x = model.Mixed_6a(x)\n",
    "    t2 = datetime.datetime.now()\n",
    "    dt1 = t2 - t1\n",
    "    print('After Mixed6A (' + str(dt1.total_seconds()) + '):', compute_mem_size(x))\n",
    "    # 17 x 17 x 768\n",
    "    t1 = datetime.datetime.now()\n",
    "    x = model.Mixed_6b(x)\n",
    "    t2 = datetime.datetime.now()\n",
    "    dt1 = t2 - t1\n",
    "    print('After Mixed6B (' + str(dt1.total_seconds()) + '):', compute_mem_size(x))\n",
    "    # 17 x 17 x 768\n",
    "    t1 = datetime.datetime.now()\n",
    "    x = model.Mixed_6c(x)\n",
    "    t2 = datetime.datetime.now()\n",
    "    dt1 = t2 - t1\n",
    "    print('After Mixed6C (' + str(dt1.total_seconds()) + '):', compute_mem_size(x))\n",
    "    # 17 x 17 x 768\n",
    "    t1 = datetime.datetime.now()\n",
    "    x = model.Mixed_6d(x)\n",
    "    t2 = datetime.datetime.now()\n",
    "    dt1 = t2 - t1\n",
    "    print('After Mixed6D (' + str(dt1.total_seconds()) + '):', compute_mem_size(x))\n",
    "    # 17 x 17 x 768\n",
    "    t1 = datetime.datetime.now()\n",
    "    x = model.Mixed_6e(x)\n",
    "    t2 = datetime.datetime.now()\n",
    "    dt1 = t2 - t1\n",
    "    print('After Mixed6E (' + str(dt1.total_seconds()) + '):', compute_mem_size(x))\n",
    "    # 17 x 17 x 768\n",
    "    t1 = datetime.datetime.now()\n",
    "    x = model.Mixed_7a(x)\n",
    "    t2 = datetime.datetime.now()\n",
    "    dt1 = t2 - t1\n",
    "    print('After Mixed7A (' + str(dt1.total_seconds()) + '):', compute_mem_size(x))\n",
    "    # 8 x 8 x 1280\n",
    "    t1 = datetime.datetime.now()\n",
    "    x = model.Mixed_7b(x)\n",
    "    t2 = datetime.datetime.now()\n",
    "    dt1 = t2 - t1\n",
    "    print('After Mixed7B (' + str(dt1.total_seconds()) + '):', compute_mem_size(x))\n",
    "    # 8 x 8 x 2048\n",
    "    t1 = datetime.datetime.now()\n",
    "    x = model.Mixed_7c(x)\n",
    "    t2 = datetime.datetime.now()\n",
    "    dt1 = t2 - t1\n",
    "    print('After Mixed7C (' + str(dt1.total_seconds()) + '):', compute_mem_size(x))\n",
    "    # 8 x 8 x 2048\n",
    "    t1 = datetime.datetime.now()\n",
    "    x = F.avg_pool2d(x, kernel_size=8)\n",
    "    t2 = datetime.datetime.now()\n",
    "    dt1 = t2 - t1\n",
    "    print('After AvgPool2d (' + str(dt1.total_seconds()) + '):', compute_mem_size(x))\n",
    "    # 1 x 1 x 2048\n",
    "    x = F.dropout(x, training=model.training)\n",
    "    # 1 x 1 x 2048\n",
    "    x = x.view(x.size(0), -1)\n",
    "    # 2048\n",
    "    t1 = datetime.datetime.now()\n",
    "    x = model.fc(x)\n",
    "    t2 = datetime.datetime.now()\n",
    "    dt1 = t2 - t1\n",
    "    print('After FC (' + str(dt1.total_seconds()) + '):', compute_mem_size(x))\n",
    "    # 1000 (num_classes)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image size:  1072812.0\n",
      "After Conv2d1a (0.004124): 2841728.0\n",
      "After Conv2d2a (0.010699): 2765952.0\n",
      "After Conv2d2b (0.020572): 5531904.0\n",
      "After MaxPool2d (0.014877): 1364224.0\n",
      "After Conv2d3B (0.00457): 1705280.0\n",
      "After Conv2d4A (0.029353): 3871488.0\n",
      "After MaxPool2D (0.439989): 940800.0\n",
      "After Mixed5B (0.026572): 1254400.0\n",
      "After Mixed5C (0.03094): 1411200.0\n",
      "After Mixed5D (0.030154): 1411200.0\n",
      "After Mixed6A (0.018021): 887808.0\n",
      "After Mixed6B (0.02706): 887808.0\n",
      "After Mixed6C (0.0294): 887808.0\n",
      "After Mixed6D (0.033287): 887808.0\n",
      "After Mixed6E (0.040299): 887808.0\n",
      "After Mixed7A (0.016253): 327680.0\n",
      "After Mixed7B (0.02211): 524288.0\n",
      "After Mixed7C (0.027271): 524288.0\n",
      "After AvgPool2d (0.000297): 8192.0\n",
      "After FC (0.000746): 4000.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "inception_model.eval()\n",
    "for batch in inception_eval_loader:\n",
    "    inception_measure_forward(inception_model, batch)\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "imagenet_data = ImageFolder('val/', transforms.Compose([\n",
    "        transforms.Resize((299, 299)),\n",
    "#         transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        normalize]))\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    imagenet_data,\n",
    "    batch_size=1,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "Test accuracy: 22.885572139303484\n"
     ]
    }
   ],
   "source": [
    "inception_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "for batch in data_loader:\n",
    "    data, label = batch\n",
    "    result = inception_model(data)\n",
    "    if (torch.argmax(result) == label[0]):\n",
    "        correct += 1\n",
    "    total += 1\n",
    "    print(total)\n",
    "    if total > 200:\n",
    "        break\n",
    "print('Test accuracy:', (float(correct) / total) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 0., 0., 0., 1.]),\n",
       " array([1. , 1.6, 2.2, 2.8, 3.4, 4. ]),\n",
       " <a list of 5 Patch objects>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([1,4], bins=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch]",
   "language": "python",
   "name": "conda-env-torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
